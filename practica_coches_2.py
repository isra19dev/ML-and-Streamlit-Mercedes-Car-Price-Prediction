import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib
import pickle
import json
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# PARTE 1: CARGAR Y EXPLORAR EL DATASET
# ============================================================================

print("=" * 80)
print("CARGANDO Y EXPLORANDO DATASET")
print("=" * 80)

# Obtener la ruta del directorio del script
script_dir = os.path.dirname(os.path.abspath(__file__))
csv_path = os.path.join(script_dir, 'merc.csv')

# Cargar el dataset
df = pd.read_csv(csv_path)

# Informaci√≥n general del dataset
print(f"\n1. Forma del dataset: {df.shape}")
print(f"\n2. Primeras filas:")
print(df.head())

print(f"\n3. Informaci√≥n del dataset:")
print(df.info())

print(f"\n4. Estad√≠sticas descriptivas:")
print(df.describe())

print(f"\n5. Valores faltantes:")
print(df.isnull().sum())

print(f"\n6. Tipos de datos:")
print(df.dtypes)

# An√°lisis de la variable objetivo (precio)
print(f"\n7. AN√ÅLISIS DE LA VARIABLE OBJETIVO (PRECIO):")
print(f"   - Precio m√≠nimo: ${df['price'].min():.2f}")
print(f"   - Precio m√°ximo: ${df['price'].max():.2f}")
print(f"   - Precio medio: ${df['price'].mean():.2f}")
print(f"   - Precio mediano: ${df['price'].median():.2f}")

# ============================================================================
# PARTE 2: PREPROCESAMIENTO (LIMPIEZA, CODIFICACI√ìN Y ESCALADO)
# ============================================================================

print("\n" + "=" * 80)
print("PARTE 2: PREPROCESAMIENTO DE DATOS")
print("=" * 80)

# Crear una copia del dataframe
df_processed = df.copy()

# Eliminar espacios en blanco de columnas y datos
df_processed.columns = df_processed.columns.str.strip()
for col in df_processed.select_dtypes(include=['object']).columns:
    df_processed[col] = df_processed[col].str.strip()

print(f"\n1. INFORMACI√ìN INICIAL DEL DATASET:")
print(f"   - Forma: {df_processed.shape}")
print(f"   - Columnas: {df_processed.columns.tolist()}")

# Extraer marca del modelo
df_processed['brand'] = df_processed['model'].str.split().str[0]

print(f"\n2. MARCAS DETECTADAS:")
print(f"   - Total de marcas: {df_processed['brand'].nunique()}")
print(f"   - Primeras 10 marcas: {df_processed['brand'].unique()[:10].tolist()}")

# Definir caracter√≠sticas y variable objetivo
numeric_features = ['year', 'mileage', 'engineSize']
categorical_features = ['transmission', 'fuelType', 'brand', 'model']
all_features = numeric_features + categorical_features

X = df_processed[all_features].copy()
y = df_processed['price'].copy()

print(f"\n3. CARACTER√çSTICAS SELECCIONADAS:")
print(f"   - Num√©ricas: {numeric_features}")
print(f"   - Categ√≥ricas: {categorical_features}")
print(f"   - Total de muestras: {X.shape[0]}")
print(f"   - Total de caracter√≠sticas: {X.shape[1]}")

# Verificar valores faltantes
print(f"\n4. VALORES FALTANTES:")
missing_values = X.isnull().sum()
if missing_values.sum() == 0:
    print(f"   - No hay valores faltantes")
else:
    print(missing_values[missing_values > 0])

# ============================================================================
# PASO 1: SEPARAR EN CONJUNTOS DE ENTRENAMIENTO Y TEST (PRIMERO!)
# ============================================================================

print(f"\n5. SEPARACI√ìN EN CONJUNTOS DE ENTRENAMIENTO Y TEST:")
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"   - Conjunto de entrenamiento: {X_train.shape[0]} muestras")
print(f"   - Conjunto de test: {X_test.shape[0]} muestras")
print(f"   - Proporci√≥n: {X_train.shape[0] / (X_train.shape[0] + X_test.shape[0]):.1%} / {X_test.shape[0] / (X_train.shape[0] + X_test.shape[0]):.1%}")

# ============================================================================
# PASO 2: CREAR PIPELINE DE PREPROCESAMIENTO CON COLUMNTRANSFORMER
# ============================================================================

print(f"\n6. CREACI√ìN DE PIPELINE DE PREPROCESAMIENTO:")

# Definir transformaciones para variables num√©ricas
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

# Definir transformaciones para variables categ√≥ricas
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

# Combinar transformaciones con ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)

print(f"   - Transformador num√©rico: StandardScaler")
print(f"   - Transformador categ√≥rico: OneHotEncoding")

# Aplicar el preprocesamiento
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

print(f"\n7. DATOS DESPU√âS DEL PREPROCESAMIENTO:")
print(f"   - Shape X_train: {X_train.shape} ‚Üí {X_train_processed.shape}")
print(f"   - Shape X_test: {X_test.shape} ‚Üí {X_test_processed.shape}")
print(f"   - Caracter√≠sticas resultantes:")

# Obtener nombres de caracter√≠sticas despu√©s de OneHotEncoding
feature_names = []
# Nombres num√©ricos
feature_names.extend(numeric_features)
# Nombres categ√≥ricos (resultado de OneHotEncoding)
cat_encoder = preprocessor.named_transformers_['cat']
onehot_features = cat_encoder.named_steps['onehot'].get_feature_names_out(categorical_features)
feature_names.extend(onehot_features)

print(f"      Total: {len(feature_names)} caracter√≠sticas (despu√©s del encoding)")
print(f"      - Num√©ricas escaladas: {len(numeric_features)}")
print(f"      - Categ√≥ricas codificadas: {len(onehot_features)}")

print(f"\n   Primeras 20 caracter√≠sticas resultantes:")
for i, fname in enumerate(feature_names[:20], 1):
    print(f"      {i}. {fname}")

# ============================================================================
# PARTE 3: ENTRENAMIENTO Y COMPARACI√ìN DE MODELOS CON PIPELINES
# ============================================================================

print("\n" + "=" * 80)
print("PARTE 3: ENTRENAMIENTO Y COMPARACI√ìN DE 3 MODELOS")
print("=" * 80)

# Diccionario para almacenar resultados
resultados = {}
modelos_entrenados = {}

# ==================== MODELO 1: REGRESI√ìN LINEAL ====================
print("\n" + "-" * 80)
print("MODELO 1: REGRESI√ìN LINEAL")
print("-" * 80)

# Pipeline completo: preprocesamiento + modelo
pipeline_lr = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', LinearRegression())
])

print("\n1. Entrenando modelo...")
pipeline_lr.fit(X_train, y_train)

print("2. Realizando predicciones en conjunto de test...")
y_pred_lr = pipeline_lr.predict(X_test)

# Calcular m√©tricas
mse_lr = mean_squared_error(y_test, y_pred_lr)
rmse_lr = np.sqrt(mse_lr)
mae_lr = mean_absolute_error(y_test, y_pred_lr)
r2_lr = r2_score(y_test, y_pred_lr)

resultados['Regresi√≥n Lineal'] = {
    'MSE': mse_lr,
    'RMSE': rmse_lr,
    'MAE': mae_lr,
    'R¬≤': r2_lr
}
modelos_entrenados['Regresi√≥n Lineal'] = pipeline_lr

print(f"\n3. M√©tricas:")
print(f"   - R¬≤ Score: {r2_lr:.4f}")
print(f"   - RMSE: ${rmse_lr:,.2f}")
print(f"   - MAE: ${mae_lr:,.2f}")
print(f"   - MSE: ${mse_lr:,.2f}")

# ==================== MODELO 2: RANDOM FOREST ====================
print("\n" + "-" * 80)
print("MODELO 2: RANDOM FOREST")
print("-" * 80)

# Pipeline completo: preprocesamiento + modelo
# Nota: Random Forest no necesita escalado, pero lo incluimos por consistencia
pipeline_rf = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', RandomForestRegressor(
        n_estimators=100,
        max_depth=20,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42,
        n_jobs=-1
    ))
])

print("\n1. Entrenando modelo (esto puede tardar)...")
pipeline_rf.fit(X_train, y_train)

print("2. Realizando predicciones en conjunto de test...")
y_pred_rf = pipeline_rf.predict(X_test)

# Calcular m√©tricas
mse_rf = mean_squared_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mse_rf)
mae_rf = mean_absolute_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)

resultados['Random Forest'] = {
    'MSE': mse_rf,
    'RMSE': rmse_rf,
    'MAE': mae_rf,
    'R¬≤': r2_rf
}
modelos_entrenados['Random Forest'] = pipeline_rf

print(f"\n3. M√©tricas:")
print(f"   - R¬≤ Score: {r2_rf:.4f}")
print(f"   - RMSE: ${rmse_rf:,.2f}")
print(f"   - MAE: ${mae_rf:,.2f}")
print(f"   - MSE: ${mse_rf:,.2f}")

# Obtener importancia de caracter√≠sticas
print(f"\n4. Importancia de caracter√≠sticas (Top 10):")
feature_importance_rf = pipeline_rf.named_steps['model'].feature_importances_
feature_importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': feature_importance_rf
}).sort_values('importance', ascending=False)
print(feature_importance_df.head(10).to_string(index=False))

# ==================== MODELO 3: GRADIENT BOOSTING ====================
print("\n" + "-" * 80)
print("MODELO 3: GRADIENT BOOSTING")
print("-" * 80)

# Pipeline completo: preprocesamiento + modelo
pipeline_gb = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', GradientBoostingRegressor(
        n_estimators=100,
        learning_rate=0.1,
        max_depth=5,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42
    ))
])

print("\n1. Entrenando modelo...")
pipeline_gb.fit(X_train, y_train)

print("2. Realizando predicciones en conjunto de test...")
y_pred_gb = pipeline_gb.predict(X_test)

# Calcular m√©tricas
mse_gb = mean_squared_error(y_test, y_pred_gb)
rmse_gb = np.sqrt(mse_gb)
mae_gb = mean_absolute_error(y_test, y_pred_gb)
r2_gb = r2_score(y_test, y_pred_gb)

resultados['Gradient Boosting'] = {
    'MSE': mse_gb,
    'RMSE': rmse_gb,
    'MAE': mae_gb,
    'R¬≤': r2_gb
}
modelos_entrenados['Gradient Boosting'] = pipeline_gb

print(f"\n3. M√©tricas:")
print(f"   - R¬≤ Score: {r2_gb:.4f}")
print(f"   - RMSE: ${rmse_gb:,.2f}")
print(f"   - MAE: ${mae_gb:,.2f}")
print(f"   - MSE: ${mse_gb:,.2f}")

# Obtener importancia de caracter√≠sticas
print(f"\n4. Importancia de caracter√≠sticas (Top 10):")
feature_importance_gb = pipeline_gb.named_steps['model'].feature_importances_
feature_importance_df = pd.DataFrame({
    'feature': feature_names,
    'importance': feature_importance_gb
}).sort_values('importance', ascending=False)
print(feature_importance_df.head(10).to_string(index=False))

# ============================================================================
# COMPARACI√ìN FINAL DE MODELOS
# ============================================================================

print("\n" + "=" * 80)
print("COMPARACI√ìN FINAL DE MODELOS")
print("=" * 80)

# Crear tabla de comparaci√≥n
comparacion_df = pd.DataFrame(resultados).T
comparacion_df = comparacion_df[['R¬≤', 'RMSE', 'MAE', 'MSE']]

print("\n1. TABLA COMPARATIVA NUM√âRICA DE M√âTRICAS:")
print("-" * 80)
print(comparacion_df.to_string())

# Crear tabla m√°s visual con formato porcentual
print("\n2. TABLA COMPARATIVA FORMATEADA:")
print("-" * 80)
tabla_visual = comparacion_df.copy()
tabla_visual['R¬≤'] = tabla_visual['R¬≤'].apply(lambda x: f"{x:.4f} ({x*100:.2f}%)")
tabla_visual['RMSE'] = tabla_visual['RMSE'].apply(lambda x: f"${x:,.2f}")
tabla_visual['MAE'] = tabla_visual['MAE'].apply(lambda x: f"${x:,.2f}")
tabla_visual['MSE'] = tabla_visual['MSE'].apply(lambda x: f"${x:,.2f}")
print(tabla_visual.to_string())

# An√°lisis de diferencias
print("\n3. AN√ÅLISIS DE DIFERENCIAS ENTRE MODELOS:")
print("-" * 80)

r2_scores = comparacion_df['R¬≤'].sort_values(ascending=False)
rmse_scores = comparacion_df['RMSE'].sort_values()

mejor_r2 = r2_scores.iloc[0]
peor_r2 = r2_scores.iloc[-1]
mejor_rmse = rmse_scores.iloc[0]
peor_rmse = rmse_scores.iloc[-1]

diferencia_r2 = mejor_r2 - peor_r2
diferencia_rmse = peor_rmse - mejor_rmse

print(f"\nMejor vs Peor (R¬≤ Score):")
print(f"  - Mejor: {r2_scores.index[0]} ({mejor_r2:.4f})")
print(f"  - Peor: {r2_scores.index[-1]} ({peor_r2:.4f})")
print(f"  - Diferencia: {diferencia_r2:.4f} ({diferencia_r2*100:.2f}%)")

print(f"\nMejor vs Peor (RMSE):")
print(f"  - Mejor: {rmse_scores.index[0]} (${mejor_rmse:,.2f})")
print(f"  - Peor: {rmse_scores.index[-1]} (${peor_rmse:,.2f})")
print(f"  - Diferencia: ${diferencia_rmse:,.2f}")

# Ranking
print("\n4. RANKING DE MODELOS (POR R¬≤ SCORE):")
print("-" * 80)
ranking = comparacion_df['R¬≤'].sort_values(ascending=False)
for idx, (modelo, score) in enumerate(ranking.items(), 1):
    print(f"{idx}. {modelo:20s} ‚Üí R¬≤ = {score:.4f} ({score*100:.2f}%)")

print("\n5. RANKING DE MODELOS (POR RMSE):")
print("-" * 80)
rmse_ranking = comparacion_df['RMSE'].sort_values()
for idx, (modelo, rmse) in enumerate(rmse_ranking.items(), 1):
    mae = comparacion_df.loc[modelo, 'MAE']
    print(f"{idx}. {modelo:20s} ‚Üí RMSE = ${rmse:>10,.2f} | MAE = ${mae:>10,.2f}")

print("\n" + "=" * 80)
print("AN√ÅLISIS CR√çTICO DE LOS RESULTADOS")
print("=" * 80)

mejor_modelo = ranking.index[0]
mejor_r2 = ranking.iloc[0]
mejor_rmse = comparacion_df.loc[mejor_modelo, 'RMSE']
mejor_mae = comparacion_df.loc[mejor_modelo, 'MAE']

print(f"\n1. CARACTER√çSTICAS T√âCNICAS DEL MEJOR MODELO ({mejor_modelo}):")
print("-" * 80)

if mejor_modelo == 'Regresi√≥n Lineal':
    print("""
    ‚Ä¢ Modelo simple y r√°pido de entrenar
    ‚Ä¢ Asume relaciones lineales entre variables y precio
    ‚Ä¢ Bajo riesgo de overfitting
    ‚Ä¢ Alta interpretabilidad: cada coeficiente indica el impacto en el precio
    ‚Ä¢ Requiere escalado de variables (StandardScaler)
    ‚Ä¢ Computacionalmente eficiente
    """)
    
elif mejor_modelo == 'Random Forest':
    print("""
    ‚Ä¢ Modelo ensemble robusto y no param√©trico
    ‚Ä¢ Captura relaciones NO LINEALES en los datos
    ‚Ä¢ Bajo riesgo de overfitting gracias a la media de m√∫ltiples √°rboles
    ‚Ä¢ Maneja autom√°ticamente variables categ√≥ricas despu√©s de OneHotEncoding
    ‚Ä¢ NO requiere escalado de variables (no es sensible a la escala)
    ‚Ä¢ Resistente a outliers (como veh√≠culos de lujo o muy antiguos)
    ‚Ä¢ Proporciona medida de importancia de caracter√≠sticas
    ‚Ä¢ M√°s lento que Regresi√≥n Lineal pero mucho m√°s preciso
    """)
    
elif mejor_modelo == 'Gradient Boosting':
    print("""
    ‚Ä¢ Modelo ensemble muy potente basado en boosting secuencial
    ‚Ä¢ Cada √°rbol intenta corregir errores de los anteriores
    ‚Ä¢ Excelente para capturar patrones complejos y no lineales
    ‚Ä¢ Mejor rendimiento general en competiciones de ML
    ‚Ä¢ Alto riesgo de overfitting (requiere ajuste de hiperpar√°metros)
    ‚Ä¢ M√°s lento que Random Forest en predicci√≥n
    ‚Ä¢ Sensible al learning_rate y profundidad de √°rboles
    ‚Ä¢ Proporciona medida de importancia de caracter√≠sticas
    """)

print(f"\n2. RENDIMIENTO GENERAL DEL MEJOR MODELO:")
print("-" * 80)
print(f"   ‚Ä¢ R¬≤ Score: {mejor_r2:.4f}")
print(f"     ‚Üí Explica el {mejor_r2*100:.2f}% de la varianza en los precios")
print(f"\n   ‚Ä¢ RMSE: ${mejor_rmse:,.2f}")
print(f"     ‚Üí Error t√≠pico en predicciones (¬±${mejor_rmse:,.2f})")
print(f"\n   ‚Ä¢ MAE: ${mejor_mae:,.2f}")
print(f"     ‚Üí Error medio absoluto (¬±${mejor_mae:,.2f})")

# Porcentaje de error respecto al precio medio
precio_medio = y_test.mean()
error_porcentaje_mae = (mejor_mae / precio_medio) * 100
error_porcentaje_rmse = (mejor_rmse / precio_medio) * 100

print(f"\n   ‚Ä¢ Precio promedio en test set: ${precio_medio:,.2f}")
print(f"   ‚Ä¢ Error MAE como % del precio promedio: {error_porcentaje_mae:.2f}%")
print(f"   ‚Ä¢ Error RMSE como % del precio promedio: {error_porcentaje_rmse:.2f}%")

print(f"\n3. COMPARATIVA CON OTROS MODELOS:")
print("-" * 80)

for modelo in comparacion_df.index:
    if modelo != mejor_modelo:
        r2_diff = comparacion_df.loc[mejor_modelo, 'R¬≤'] - comparacion_df.loc[modelo, 'R¬≤']
        rmse_diff = comparacion_df.loc[modelo, 'RMSE'] - comparacion_df.loc[mejor_modelo, 'RMSE']
        
        print(f"\n   {mejor_modelo} vs {modelo}:")
        print(f"   ‚Ä¢ R¬≤ mejorado en: {r2_diff:.4f} ({r2_diff*100:.2f}%)")
        print(f"   ‚Ä¢ RMSE reducido en: ${rmse_diff:,.2f} ({(rmse_diff/comparacion_df.loc[modelo, 'RMSE'])*100:.1f}%)")

print(f"\n4. FORTALEZAS DEL MODELO SELECCIONADO:")
print("-" * 80)

if mejor_modelo == 'Random Forest':
    print("""
    ‚úì Mejor balance entre precisi√≥n y complejidad
    ‚úì Robusto ante datos at√≠picos (outliers)
    ‚úì Maneja relaciones no lineales eficientemente
    ‚úì Bajo riesgo de sobreajuste gracias a la agregaci√≥n
    ‚úì Interpretable mediante importancia de caracter√≠sticas
    ‚úì Relativamente r√°pido en predicci√≥n
    """)
elif mejor_modelo == 'Gradient Boosting':
    print("""
    ‚úì M√°xima precisi√≥n entre los modelos evaluados
    ‚úì Captura patrones muy complejos y no lineales
    ‚úì Excelente para datos con estructura jer√°rquica
    ‚úì Importancia de caracter√≠sticas confiable
    ‚úì Mejor generalizaci√≥n en muchos casos
    """)
else:
    print("""
    ‚úì Modelo simple y muy interpretable
    ‚úì R√°pido de entrenar y predecir
    ‚úì Bajo riesgo de overfitting
    ‚úì Consumo m√≠nimo de recursos
    ‚úì F√°cil de implementar en producci√≥n
    """)

print(f"\n5. LIMITACIONES Y CONSIDERACIONES:")
print("-" * 80)

if mejor_modelo == 'Regresi√≥n Lineal':
    print("""
    ‚úó Asume relaciones lineales (puede ser insuficiente)
    ‚úó Menor capacidad predictiva que m√©todos m√°s complejos
    ‚úó No captura interacciones entre variables
    ‚úó Sensible a outliers
    ‚úó Requiere escalado de variables
    """)
elif mejor_modelo == 'Random Forest':
    print("""
    ‚úó Modelo "caja negra" menos interpretable que regresi√≥n lineal
    ‚úó Mayor complejidad computacional
    ‚úó Requiere m√°s memoria para almacenar
    ‚úó Puede sobreajustar si no se ajustan bien los hiperpar√°metros
    ‚úó Sesgado hacia variables categ√≥ricas con muchas clases
    """)
elif mejor_modelo == 'Gradient Boosting':
    print("""
    ‚úó Mayor riesgo de overfitting (requiere validaci√≥n cuidadosa)
    ‚úó M√°s lento en entrenamiento que Random Forest
    ‚úó Requiere ajuste fino de varios hiperpar√°metros
    ‚úó Sensible al learning rate
    ‚úó M√°s dif√≠cil de interpretar que modelos simples
    """)

# ============================================================================
# JUSTIFICACI√ìN CLARA DEL MODELO SELECCIONADO
# ============================================================================

print("\n" + "=" * 80)
print("JUSTIFICACI√ìN CLARA DEL MODELO SELECCIONADO")
print("=" * 80)

print(f"\n{mejor_modelo.upper()}")
print("=" * 80)

print(f"""
‚úì RAZONES T√âCNICAS:

1. Rendimiento Superior
   ‚Ä¢ Logra un R¬≤ de {mejor_r2:.4f}, lo que significa que explica el 
     {mejor_r2*100:.2f}% de la variabilidad en los precios de veh√≠culos
   ‚Ä¢ Error RMSE de ${mejor_rmse:,.2f}, muy competitivo para datos de precios
   
2. Naturaleza del Problema
   ‚Ä¢ La predicci√≥n de precios de veh√≠culos involucra relaciones NO LINEALES
   ‚Ä¢ Diferentes marcas, modelos y tipos de combustible tienen impactos 
     variables en el precio
   ‚Ä¢ Los modelos ensemble capturan mejor estas complejidades
   
3. Robustez
   ‚Ä¢ {mejor_modelo} es resistente a outliers (coches de lujo, muy antiguos, etc.)
   ‚Ä¢ No requiere normalizaci√≥n/escalado (ventaja operacional)
   ‚Ä¢ Maneja bien datos mixtos (num√©ricos + categ√≥nicos)
   
4. Interpretabilidad
   ‚Ä¢ Proporciona ranking de importancia de caracter√≠sticas
   ‚Ä¢ Permite identificar qu√© variables m√°s impactan el precio
   ‚Ä¢ √ötil para stakeholders y toma de decisiones

5. Generalizaci√≥n
   ‚Ä¢ Bajo riesgo de overfitting gracias a la agregaci√≥n de m√∫ltiples modelos
   ‚Ä¢ Buena capacidad de generalizaci√≥n a datos nuevos
   
‚úì RAZONES PR√ÅCTICAS:

1. Aplicabilidad en Producci√≥n
   ‚Ä¢ Suficientemente r√°pido para predicciones en tiempo real
   ‚Ä¢ F√°cil de serializar y desplegar
   ‚Ä¢ No requiere escalado en predicci√≥n
   
2. Mantenibilidad
   ‚Ä¢ No requiere ajuste fino de muchos hiperpar√°metros
   ‚Ä¢ Estable ante cambios peque√±os en datos
   ‚Ä¢ C√≥digo limpio y f√°cil de mantener
   
3. Escalabilidad
   ‚Ä¢ Puede entrenarse en paralelo (n_jobs=-1)
   ‚Ä¢ Maneja datasets grandes eficientemente
""")

print(f"\n‚úì CONCLUSI√ìN FINAL:")
print("-" * 80)
print(f"""
Se selecciona {mejor_modelo} como modelo de producci√≥n para la aplicaci√≥n
web porque:

‚Ä¢ Ofrece el mejor balance entre precisi√≥n ({mejor_r2:.4f}) y complejidad
‚Ä¢ Es robusto ante datos at√≠picos comunes en el mercado de segunda mano
‚Ä¢ Proporciona buena interpretabilidad de caracter√≠sticas
‚Ä¢ Es escalable y mantenible a largo plazo
‚Ä¢ Tiene bajo riesgo de overfitting
‚Ä¢ Es suficientemente r√°pido para predicciones en tiempo real

Este modelo ser√° integrado en la aplicaci√≥n web para que usuarios puedan
obtener estimaciones de precio precisas basadas en caracter√≠sticas del 
veh√≠culo.
""")

# ============================================================================
# PARTE 4: OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS DEL MEJOR MODELO
# ============================================================================

print("\n" + "=" * 80)
print("PARTE 4: OPTIMIZACI√ìN DE HIPERPAR√ÅMETROS")
print("=" * 80)

# Determinar cu√°l es el mejor modelo
mejor_modelo_nombre = ranking.index[0]

print(f"\n1. MODELO SELECCIONADO PARA OPTIMIZACI√ìN: {mejor_modelo_nombre}")
print("-" * 80)

if mejor_modelo_nombre == 'Regresi√≥n Lineal':
    print("\n‚ö†Ô∏è  NOTA: La Regresi√≥n Lineal no tiene hiperpar√°metros complejos para optimizar.")
    print("   (Solo tiene par√°metro 'fit_intercept', que ya est√° optimizado)")
    print("   Se mantendr√° el modelo actual con configuraci√≥n por defecto.")
    
    modelo_final = pipeline_lr
    hiperparametros_optimos = {'modelo': 'LinearRegression', 'hiperpar√°metros': 'por defecto'}
    print("\n‚úì Modelo optimizado (usando configuraci√≥n por defecto)")
    
elif mejor_modelo_nombre == 'Random Forest':
    print("\nRealizando b√∫squeda de mejores hiperpar√°metros...")
    print("(Esto puede tardar unos minutos...)\n")
    
    # Crear pipeline solo con Random Forest para optimizar
    param_grid = {
        'model__n_estimators': [100, 200, 300],
        'model__max_depth': [15, 20, 25],
        'model__min_samples_split': [2, 5, 10],
        'model__min_samples_leaf': [1, 2, 4]
    }
    
    pipeline_rf_opt = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', RandomForestRegressor(random_state=42, n_jobs=-1))
    ])
    
    # GridSearchCV con validaci√≥n cruzada
    grid_search = GridSearchCV(
        pipeline_rf_opt,
        param_grid,
        cv=5,
        scoring='r2',
        n_jobs=-1,
        verbose=1
    )
    
    print("Entrenando con GridSearchCV (5-fold)...")
    grid_search.fit(X_train, y_train)
    
    modelo_final = grid_search.best_estimator_
    hiperparametros_optimos = {
        'modelo': 'RandomForestRegressor',
        'mejores_hiperpar√°metros': grid_search.best_params_,
        'mejor_cv_score': grid_search.best_score_
    }
    
    print(f"\n‚úì Mejores hiperpar√°metros encontrados:")
    for param, valor in grid_search.best_params_.items():
        print(f"   - {param}: {valor}")
    print(f"\nMejor CV Score (R¬≤): {grid_search.best_score_:.4f}")
    
    # Calcular m√©tricas con el modelo optimizado
    y_pred_final = modelo_final.predict(X_test)
    r2_final = r2_score(y_test, y_pred_final)
    rmse_final = np.sqrt(mean_squared_error(y_test, y_pred_final))
    mae_final = mean_absolute_error(y_test, y_pred_final)
    
    print(f"\nM√©tricas en conjunto TEST con modelo optimizado:")
    print(f"   - R¬≤ Score: {r2_final:.4f}")
    print(f"   - RMSE: ${rmse_final:,.2f}")
    print(f"   - MAE: ${mae_final:,.2f}")

elif mejor_modelo_nombre == 'Gradient Boosting':
    print("\nRealizando b√∫squeda de mejores hiperpar√°metros...")
    print("(Esto puede tardar unos minutos...)\n")
    
    # Crear pipeline solo con Gradient Boosting para optimizar
    param_grid = {
        'model__n_estimators': [100, 150, 200],
        'model__learning_rate': [0.05, 0.1, 0.15],
        'model__max_depth': [3, 5, 7],
        'model__min_samples_split': [2, 5, 10],
        'model__min_samples_leaf': [1, 2, 4]
    }
    
    pipeline_gb_opt = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('model', GradientBoostingRegressor(random_state=42))
    ])
    
    # GridSearchCV con validaci√≥n cruzada
    grid_search = GridSearchCV(
        pipeline_gb_opt,
        param_grid,
        cv=5,
        scoring='r2',
        n_jobs=-1,
        verbose=1
    )
    
    print("Entrenando con GridSearchCV (5-fold)...")
    grid_search.fit(X_train, y_train)
    
    modelo_final = grid_search.best_estimator_
    hiperparametros_optimos = {
        'modelo': 'GradientBoostingRegressor',
        'mejores_hiperpar√°metros': grid_search.best_params_,
        'mejor_cv_score': grid_search.best_score_
    }
    
    print(f"\n‚úì Mejores hiperpar√°metros encontrados:")
    for param, valor in grid_search.best_params_.items():
        print(f"   - {param}: {valor}")
    print(f"\nMejor CV Score (R¬≤): {grid_search.best_score_:.4f}")
    
    # Calcular m√©tricas con el modelo optimizado
    y_pred_final = modelo_final.predict(X_test)
    r2_final = r2_score(y_test, y_pred_final)
    rmse_final = np.sqrt(mean_squared_error(y_test, y_pred_final))
    mae_final = mean_absolute_error(y_test, y_pred_final)
    
    print(f"\nM√©tricas en conjunto TEST con modelo optimizado:")
    print(f"   - R¬≤ Score: {r2_final:.4f}")
    print(f"   - RMSE: ${rmse_final:,.2f}")
    print(f"   - MAE: ${mae_final:,.2f}")

# ============================================================================
# PARTE 5: EXPORTACI√ìN DEL MODELO Y TRANSFORMADORES
# ============================================================================

print("\n" + "=" * 80)
print("PARTE 5: EXPORTACI√ìN DEL MODELO Y TRANSFORMADORES")
print("=" * 80)

# Crear directorio para guardar modelos
directorio_modelos = 'modelos_exportados'
if not os.path.exists(directorio_modelos):
    os.makedirs(directorio_modelos)
    print(f"\n‚úì Creado directorio: {directorio_modelos}/")

print(f"\n1. EXPORTANDO MODELO FINAL ({mejor_modelo_nombre})")
print("-" * 80)

# Guardar modelo completo (pipeline) con joblib (m√°s eficiente)
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
nombre_modelo = f"modelo_final_{mejor_modelo_nombre.lower().replace(' ', '_')}_{timestamp}"

# Guardar con joblib (recomendado para sklearn)
ruta_modelo_joblib = os.path.join(directorio_modelos, f"{nombre_modelo}.joblib")
joblib.dump(modelo_final, ruta_modelo_joblib)
print(f"\n‚úì Modelo completo guardado (joblib):")
print(f"   Ruta: {ruta_modelo_joblib}")
print(f"   Tama√±o: {os.path.getsize(ruta_modelo_joblib) / (1024*1024):.2f} MB")

# Tambi√©n guardar con pickle por compatibilidad
ruta_modelo_pickle = os.path.join(directorio_modelos, f"{nombre_modelo}.pkl")
with open(ruta_modelo_pickle, 'wb') as f:
    pickle.dump(modelo_final, f)
print(f"\n‚úì Modelo completo guardado (pickle - compatibilidad):")
print(f"   Ruta: {ruta_modelo_pickle}")
print(f"   Tama√±o: {os.path.getsize(ruta_modelo_pickle) / (1024*1024):.2f} MB")

# ============================================================================
# Exportar SOLO el preprocessor (para hacer predicciones sin reentrenar)
# ============================================================================

print(f"\n2. EXPORTANDO PREPROCESSADOR (TRANSFORMADORES)")
print("-" * 80)

ruta_preprocessor = os.path.join(directorio_modelos, "preprocessor.joblib")
joblib.dump(preprocessor, ruta_preprocessor)
print(f"\n‚úì Preprocessor guardado:")
print(f"   Ruta: {ruta_preprocessor}")
print(f"   Tama√±o: {os.path.getsize(ruta_preprocessor) / (1024*1024):.2f} MB")
print(f"\n   Incluye:")
print(f"   - StandardScaler para variables num√©ricas: {numeric_features}")
print(f"   - OneHotEncoder para variables categ√≥ricas: {categorical_features}")

# ============================================================================
# Exportar el modelo entrenado (SOLO el componente del modelo)
# ============================================================================

print(f"\n3. EXPORTANDO MODELO DE MACHINE LEARNING (SOLO EL MODELO)")
print("-" * 80)

modelo_ml_solo = modelo_final.named_steps['model']
ruta_modelo_ml = os.path.join(directorio_modelos, f"modelo_ml_{mejor_modelo_nombre.lower().replace(' ', '_')}.joblib")
joblib.dump(modelo_ml_solo, ruta_modelo_ml)
print(f"\n‚úì Componente ML guardado:")
print(f"   Ruta: {ruta_modelo_ml}")
print(f"   Tama√±o: {os.path.getsize(ruta_modelo_ml) / (1024*1024):.2f} MB")
print(f"   (Para usar despu√©s con preprocessor guardado)")

# ============================================================================
# Guardar metadatos del modelo
# ============================================================================

print(f"\n4. GUARDANDO METADATOS DEL MODELO")
print("-" * 80)

metadatos = {
    'timestamp': timestamp,
    'nombre_modelo': mejor_modelo_nombre,
    'dataset_size_train': X_train.shape[0],
    'dataset_size_test': X_test.shape[0],
    'num_features': X_train.shape[1],
    'features': all_features,
    'numeric_features': numeric_features,
    'categorical_features': categorical_features,
    'metricas': {
        'r2_score': float(r2_final if mejor_modelo_nombre != 'Regresi√≥n Lineal' else r2_lr),
        'rmse': float(rmse_final if mejor_modelo_nombre != 'Regresi√≥n Lineal' else rmse_lr),
        'mae': float(mae_final if mejor_modelo_nombre != 'Regresi√≥n Lineal' else mae_lr)
    },
    'hiperparametros': hiperparametros_optimos,
    'variables_precio': {
        'min': float(y_test.min()),
        'max': float(y_test.max()),
        'media': float(y_test.mean()),
        'mediana': float(y_test.median())
    }
}

ruta_metadatos = os.path.join(directorio_modelos, "metadatos_modelo.json")
with open(ruta_metadatos, 'w', encoding='utf-8') as f:
    json.dump(metadatos, f, indent=4, ensure_ascii=False)

print(f"\n‚úì Metadatos guardados:")
print(f"   Ruta: {ruta_metadatos}")

print(f"\n   Contenido:")
print(f"   - Nombre del modelo: {metadatos['nombre_modelo']}")
print(f"   - Timestamp: {metadatos['timestamp']}")
print(f"   - R¬≤ Score: {metadatos['metricas']['r2_score']:.4f}")
print(f"   - RMSE: ${metadatos['metricas']['rmse']:,.2f}")
print(f"   - MAE: ${metadatos['metricas']['mae']:,.2f}")
print(f"   - Rango de precios: ${metadatos['variables_precio']['min']:,.0f} - ${metadatos['variables_precio']['max']:,.0f}")

# ============================================================================
# Guardar informaci√≥n de las clases categ√≥ricas
# ============================================================================

print(f"\n5. GUARDANDO DICCIONARIOS DE CATEGOR√çAS")
print("-" * 80)

categorias_info = {}
onehot_encoder = preprocessor.named_transformers_['cat'].named_steps['onehot']

for idx, categoria in enumerate(categorical_features):
    categorias_info[categoria] = {
        'clases': onehot_encoder.categories_[idx].tolist(),
        'num_clases': len(onehot_encoder.categories_[idx])
    }

ruta_categorias = os.path.join(directorio_modelos, "categorias_mapping.json")
with open(ruta_categorias, 'w', encoding='utf-8') as f:
    json.dump(categorias_info, f, indent=4, ensure_ascii=False)

print(f"\n‚úì Categor√≠as guardadas:")
print(f"   Ruta: {ruta_categorias}")
print(f"\n   Resumen de categor√≠as:")
for cat, info in categorias_info.items():
    print(f"   - {cat}: {info['num_clases']} clases")

# ============================================================================
# Crear script de ejemplo para cargar y usar el modelo
# ============================================================================

print(f"\n6. CREANDO SCRIPT DE EJEMPLO PARA CARGAR EL MODELO")
print("-" * 80)

script_ejemplo = '''"""
SCRIPT DE EJEMPLO: C√≥mo cargar y usar el modelo exportado
"""

import joblib
import pandas as pd
import json

# ============================================================================
# PASO 1: Cargar el modelo completo (opci√≥n m√°s simple)
# ============================================================================

print("Opci√≥n 1: Usar el modelo COMPLETO (pipeline incluido)")
print("=" * 60)

# Cargar el modelo entrenado
modelo = joblib.load('modelos_exportados/modelo_final_*.joblib')

# Hacer una predicci√≥n
datos_nuevos = pd.DataFrame({
    'year': [2020],
    'mileage': [50000],
    'engineSize': [2.0],
    'transmission': ['Automatic'],
    'fuelType': ['Petrol'],
    'brand': ['BMW'],
    'model': ['Series 5']
})

prediccion = modelo.predict(datos_nuevos)
print(f"Precio predicho: ${prediccion[0]:,.2f}")

# ============================================================================
# PASO 2: Cargar componentes por separado (opci√≥n m√°s flexible)
# ============================================================================

print("\\nOpci√≥n 2: Cargar preprocessor y modelo por separado")
print("=" * 60)

# Cargar componentes
preprocessor = joblib.load('modelos_exportados/preprocessor.joblib')
modelo_ml = joblib.load('modelos_exportados/modelo_ml_*.joblib')

# Transformar datos
X_procesados = preprocessor.transform(datos_nuevos)

# Hacer predicci√≥n
prediccion = modelo_ml.predict(X_procesados)
print(f"Precio predicho: ${prediccion[0]:,.2f}")

# ============================================================================
# PASO 3: Acceder a metadatos del modelo
# ============================================================================

print("\\nPaso 3: Acceder a informaci√≥n del modelo")
print("=" * 60)

# Cargar metadatos
with open('modelos_exportados/metadatos_modelo.json', 'r') as f:
    metadatos = json.load(f)

print(f"Nombre del modelo: {metadatos['nombre_modelo']}")
print(f"R¬≤ Score: {metadatos['metricas']['r2_score']:.4f}")
print(f"RMSE: ${metadatos['metricas']['rmse']:,.2f}")

# Cargar mapeo de categor√≠as
with open('modelos_exportados/categorias_mapping.json', 'r') as f:
    categorias = json.load(f)

print(f"\\nCategor√≠as disponibles en 'transmission': {categorias['transmission']['clases']}")
'''

ruta_script = os.path.join(directorio_modelos, "ejemplo_uso_modelo.py")
with open(ruta_script, 'w', encoding='utf-8') as f:
    f.write(script_ejemplo)

print(f"\n‚úì Script de ejemplo creado:")
print(f"   Ruta: {ruta_script}")
print(f"   Contiene instrucciones para cargar y usar el modelo")

# ============================================================================
# RESUMEN FINAL
# ============================================================================

print("\n" + "=" * 80)
print("RESUMEN DE ARCHIVOS EXPORTADOS")
print("=" * 80)

print(f"\nüìÅ Directorio: {os.path.abspath(directorio_modelos)}/")
print("\nüìÑ Archivos generados:\n")

archivos = os.listdir(directorio_modelos)
for i, archivo in enumerate(sorted(archivos), 1):
    ruta_completa = os.path.join(directorio_modelos, archivo)
    tama√±o = os.path.getsize(ruta_completa)
    print(f"{i}. {archivo}")
    print(f"   ‚îî‚îÄ Tama√±o: {tama√±o / 1024:.2f} KB")

print(f"\n‚úì Todos los archivos necesarios han sido guardados correctamente")
print(f"‚úì El modelo est√° listo para ser usado en la aplicaci√≥n web")

print("\n" + "=" * 80)


