import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import os
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURACIÃ“N DE ESTILO
# ============================================================================

plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

# ============================================================================
# CARGAR DATOS Y MODELO
# ============================================================================

print("=" * 80)
print("ANÃLISIS GRÃFICO DEL MODELO DE PREDICCIÃ“N DE PRECIOS")
print("=" * 80)

# Obtener rutas
script_dir = os.path.dirname(os.path.abspath(__file__))
csv_path = os.path.join(script_dir, 'merc.csv')
modelos_dir = os.path.join(script_dir, 'modelos_exportados')

# Cargar datos
print("\nğŸ“Š Cargando datos...")
df = pd.read_csv(csv_path)

# Cargar modelo
print("ğŸ¤– Cargando modelo entrenado...")
modelo_files = [f for f in os.listdir(modelos_dir)
                if f.startswith('modelo_final_') and f.endswith('.joblib')]

if not modelo_files:
    print("âŒ Error: No se encontrÃ³ el modelo. Ejecuta primero practica_coches_2.py")
    exit()

modelo_path = os.path.join(modelos_dir, modelo_files[0])
modelo = joblib.load(modelo_path)

preprocessor_path = os.path.join(modelos_dir, 'preprocessor.joblib')
preprocessor = joblib.load(preprocessor_path)

print(f"âœ… Modelo cargado: {modelo_files[0]}")

# ============================================================================
# PREPARAR DATOS
# ============================================================================

print("\nğŸ“ Preparando datos...")

# Primero, ver quÃ© columnas tiene el CSV
print(f"   Columnas disponibles: {list(df.columns)}")

# Seleccionar caracterÃ­sticas y target - basado en las columnas reales
# El modelo fue entrenado con: year, mileage, engineSize, transmission, fuelType, brand, model
# Pero el CSV tiene: model, year, price, transmission, mileage, fuelType, tax, mpg, engineSize

# Vamos a usar las columnas que tenemos
available_cols = df.columns.tolist()

# Crear la columna 'brand' a partir del 'model' si no existe
if 'brand' not in df.columns:
    print("   â„¹ï¸ Creando columna 'brand' a partir de 'model'...")
    # Extraer la primera palabra de model como brand (ej: 'A Class' -> 'A')
    df['brand'] = df['model'].str.split().str[0]
    print("   âœ… Columna 'brand' creada")

# CaracterÃ­sticas usadas en el modelo
features = ['year', 'mileage', 'engineSize', 'transmission', 'fuelType', 'brand', 'model']

# Verificar que todas las caracterÃ­sticas existan
missing_features = [f for f in features if f not in df.columns]
if missing_features:
    print(f"   âš ï¸ CaracterÃ­sticas faltantes: {missing_features}")
    features = [f for f in features if f in df.columns]

# Cargar datos
X = df[features].copy()
y = df['price'].copy()

print(f"   Datos cargados: {X.shape[0]} muestras, {X.shape[1]} caracterÃ­sticas")
print(f"   CaracterÃ­sticas: {features}")

# Dividir datos (mismo seed que en entrenamiento)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"   Train: {X_train.shape[0]} | Test: {X_test.shape[0]}")

# Preprocesar - el preprocessor maneja la transformaciÃ³n
try:
    X_train_prep = preprocessor.transform(X_train)
    X_test_prep = preprocessor.transform(X_test)
    print("   âœ… Datos preprocesados correctamente")
except Exception as e:
    print(f"   âš ï¸ Error en preprocesamiento: {str(e)}")
    print("   Intentando alternativa...")
    # Si falla, usar los datos directamente
    X_train_prep = X_train
    X_test_prep = X_test

# Hacer predicciones
print("ğŸ”® Realizando predicciones...")
y_pred_train = modelo.predict(X_train)  # El modelo incluye el preprocessor
y_pred_test = modelo.predict(X_test)    # El modelo incluye el preprocessor

# Calcular mÃ©tricas
mae_train = mean_absolute_error(y_train, y_pred_train)
mae_test = mean_absolute_error(y_test, y_pred_test)
rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))
rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))
r2_train = r2_score(y_train, y_pred_train)
r2_test = r2_score(y_test, y_pred_test)

print(f"\nâœ… Predicciones completadas")
print(f"\nğŸ“ˆ MÃ‰TRICAS DE ENTRENAMIENTO:")
print(f"   MAE Train:  ${mae_train:,.2f}")
print(f"   RMSE Train: ${rmse_train:,.2f}")
print(f"   RÂ² Train:   {r2_train:.4f}")

print(f"\nğŸ“ˆ MÃ‰TRICAS DE TEST:")
print(f"   MAE Test:   ${mae_test:,.2f}")
print(f"   RMSE Test:  ${rmse_test:,.2f}")
print(f"   RÂ² Test:    {r2_test:.4f}")

# ============================================================================
# CREAR GRÃFICAS
# ============================================================================

print("\nğŸ¨ Generando grÃ¡ficas...")

fig = plt.figure(figsize=(18, 12))

# ============================================================================
# 1. GRÃFICA 1: Predicciones vs Valores Reales (Test)
# ============================================================================

ax1 = plt.subplot(2, 3, 1)
ax1.scatter(y_test, y_pred_test, alpha=0.5, s=30, color='steelblue')
ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
         'r--', lw=2, label='PredicciÃ³n Perfecta')
ax1.set_xlabel('Precio Real ($)', fontsize=11, fontweight='bold')
ax1.set_ylabel('Precio Predicho ($)', fontsize=11, fontweight='bold')
ax1.set_title('Predicciones vs Valores Reales (Test Set)', fontsize=12, fontweight='bold')
ax1.legend()
ax1.grid(True, alpha=0.3)

# ============================================================================
# 2. GRÃFICA 2: Residuos (Errores)
# ============================================================================

ax2 = plt.subplot(2, 3, 2)
residuos_test = y_test - y_pred_test
ax2.scatter(y_pred_test, residuos_test, alpha=0.5, s=30, color='coral')
ax2.axhline(y=0, color='r', linestyle='--', lw=2)
ax2.set_xlabel('Precio Predicho ($)', fontsize=11, fontweight='bold')
ax2.set_ylabel('Residuo ($)', fontsize=11, fontweight='bold')
ax2.set_title('AnÃ¡lisis de Residuos (Test Set)', fontsize=12, fontweight='bold')
ax2.grid(True, alpha=0.3)

# ============================================================================
# 3. GRÃFICA 3: DistribuciÃ³n de Errores
# ============================================================================

ax3 = plt.subplot(2, 3, 3)
ax3.hist(residuos_test, bins=50, color='mediumseagreen', edgecolor='black', alpha=0.7)
ax3.axvline(x=0, color='r', linestyle='--', lw=2, label='Error = 0')
ax3.set_xlabel('Residuo ($)', fontsize=11, fontweight='bold')
ax3.set_ylabel('Frecuencia', fontsize=11, fontweight='bold')
ax3.set_title('DistribuciÃ³n de Errores (Test Set)', fontsize=12, fontweight='bold')
ax3.legend()
ax3.grid(True, alpha=0.3, axis='y')

# ============================================================================
# 4. GRÃFICA 4: Error Absoluto (MAE) por Rango de Precio
# ============================================================================

ax4 = plt.subplot(2, 3, 4)
errores_abs = np.abs(residuos_test)
rangos_precio = pd.cut(y_test, bins=10)
errores_por_rango = pd.DataFrame({
    'rango': rangos_precio,
    'error': errores_abs
}).groupby('rango')['error'].agg(['mean', 'std'])

rangos_labels = [f"${int(interval.left/1000)}k-${int(interval.right/1000)}k" 
                 for interval in errores_por_rango.index]

ax4.bar(range(len(errores_por_rango)), errores_por_rango['mean'], 
        yerr=errores_por_rango['std'], capsize=5, color='skyblue', 
        edgecolor='black', alpha=0.7)
ax4.set_xticks(range(len(errores_por_rango)))
ax4.set_xticklabels(rangos_labels, rotation=45, ha='right')
ax4.set_ylabel('Error Absoluto Medio ($)', fontsize=11, fontweight='bold')
ax4.set_title('MAE por Rango de Precio', fontsize=12, fontweight='bold')
ax4.grid(True, alpha=0.3, axis='y')

# ============================================================================
# 5. GRÃFICA 5: ComparaciÃ³n Train vs Test
# ============================================================================

ax5 = plt.subplot(2, 3, 5)
metricas = ['MAE', 'RMSE', 'RÂ²']
valores_train = [mae_train, rmse_train, r2_train]
valores_test = [mae_test, rmse_test, r2_test]

x = np.arange(len(metricas))
width = 0.35

ax5.bar(x - width/2, valores_train, width, label='Train', color='lightcoral', alpha=0.8)
ax5.bar(x + width/2, valores_test, width, label='Test', color='lightgreen', alpha=0.8)
ax5.set_ylabel('Valor', fontsize=11, fontweight='bold')
ax5.set_title('ComparaciÃ³n de MÃ©tricas: Train vs Test', fontsize=12, fontweight='bold')
ax5.set_xticks(x)
ax5.set_xticklabels(metricas)
ax5.legend()
ax5.grid(True, alpha=0.3, axis='y')

# ============================================================================
# 6. GRÃFICA 6: Q-Q Plot (Normalidad de residuos)
# ============================================================================

ax6 = plt.subplot(2, 3, 6)
residuos_normalizados = (residuos_test - residuos_test.mean()) / residuos_test.std()
cuantiles_teoricos = np.quantile(np.random.normal(0, 1, 10000), 
                                 np.linspace(0.01, 0.99, len(residuos_normalizados)))
cuantiles_empiricos = np.sort(residuos_normalizados)

ax6.scatter(cuantiles_teoricos, cuantiles_empiricos, alpha=0.5, s=30, color='purple')
min_val = min(cuantiles_teoricos.min(), cuantiles_empiricos.min())
max_val = max(cuantiles_teoricos.max(), cuantiles_empiricos.max())
ax6.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2, label='LÃ­nea TeÃ³rica')
ax6.set_xlabel('Cuantiles TeÃ³ricos', fontsize=11, fontweight='bold')
ax6.set_ylabel('Cuantiles EmpÃ­ricos', fontsize=11, fontweight='bold')
ax6.set_title('Q-Q Plot (Normalidad de Residuos)', fontsize=12, fontweight='bold')
ax6.legend()
ax6.grid(True, alpha=0.3)

plt.tight_layout()

# ============================================================================
# GRÃFICAS ADICIONALES - SEGUNDA PÃGINA
# ============================================================================

fig2 = plt.figure(figsize=(16, 10))

# ============================================================================
# 7. GRÃFICA 7: Box Plot de Residuos por Deciles
# ============================================================================

ax7 = plt.subplot(2, 2, 1)
deciles = pd.qcut(y_test, q=5, labels=['Muy Bajos', 'Bajos', 'Medios', 'Altos', 'Muy Altos'])
datos_boxplot = [residuos_test[deciles == cat].values for cat in deciles.unique()]

bp = ax7.boxplot(datos_boxplot, labels=['Muy Bajos', 'Bajos', 'Medios', 'Altos', 'Muy Altos'],
                 patch_artist=True)
for patch, color in zip(bp['boxes'], plt.cm.Set3(range(5))):
    patch.set_facecolor(color)
ax7.axhline(y=0, color='r', linestyle='--', lw=2)
ax7.set_ylabel('Residuo ($)', fontsize=11, fontweight='bold')
ax7.set_xlabel('CategorÃ­a de Precio', fontsize=11, fontweight='bold')
ax7.set_title('DistribuciÃ³n de Residuos por CategorÃ­a de Precio', fontsize=12, fontweight='bold')
ax7.grid(True, alpha=0.3, axis='y')

# ============================================================================
# 8. GRÃFICA 8: Histograma 2D (Densidad)
# ============================================================================

ax8 = plt.subplot(2, 2, 2)
h = ax8.hist2d(y_test, y_pred_test, bins=30, cmap='YlOrRd')
plt.colorbar(h[3], ax=ax8, label='Frecuencia')
ax8.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
         'b--', lw=2, label='PredicciÃ³n Perfecta')
ax8.set_xlabel('Precio Real ($)', fontsize=11, fontweight='bold')
ax8.set_ylabel('Precio Predicho ($)', fontsize=11, fontweight='bold')
ax8.set_title('Densidad: Predicciones vs Valores Reales', fontsize=12, fontweight='bold')
ax8.legend()

# ============================================================================
# 9. GRÃFICA 9: Error Porcentual
# ============================================================================

ax9 = plt.subplot(2, 2, 3)
error_porcentual = np.abs((y_test - y_pred_test) / y_test * 100)
ax9.hist(error_porcentual, bins=50, color='mediumpurple', edgecolor='black', alpha=0.7)
ax9.axvline(x=error_porcentual.mean(), color='r', linestyle='--', lw=2, 
            label=f'Media: {error_porcentual.mean():.2f}%')
ax9.set_xlabel('Error Porcentual (%)', fontsize=11, fontweight='bold')
ax9.set_ylabel('Frecuencia', fontsize=11, fontweight='bold')
ax9.set_title('DistribuciÃ³n de Error Porcentual', fontsize=12, fontweight='bold')
ax9.legend()
ax9.grid(True, alpha=0.3, axis='y')

# ============================================================================
# 10. GRÃFICA 10: Resumen de MÃ©tricas
# ============================================================================

ax10 = plt.subplot(2, 2, 4)
ax10.axis('off')

resumen_text = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          RESUMEN DE MÃ‰TRICAS DEL MODELO                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“Š CONJUNTO DE ENTRENAMIENTO:
   â€¢ MAE (Error Absoluto Medio):  ${mae_train:>12,.2f}
   â€¢ RMSE (Error CuadrÃ¡tico Medio):  ${rmse_train:>10,.2f}
   â€¢ RÂ² (Coeficiente de DeterminaciÃ³n): {r2_train:>6.4f}

ğŸ“Š CONJUNTO DE TEST:
   â€¢ MAE (Error Absoluto Medio):  ${mae_test:>12,.2f}
   â€¢ RMSE (Error CuadrÃ¡tico Medio):  ${rmse_test:>10,.2f}
   â€¢ RÂ² (Coeficiente de DeterminaciÃ³n): {r2_test:>6.4f}

ğŸ“ˆ ESTADÃSTICAS DE RESIDUOS (TEST):
   â€¢ Media de Residuos:  ${residuos_test.mean():>12,.2f}
   â€¢ Std Dev Residuos:   ${residuos_test.std():>12,.2f}
   â€¢ Error % Promedio:   {error_porcentual.mean():>12.2f}%

ğŸ“‰ ANÃLISIS:
   â€¢ Diferencia MAE (Train-Test): ${mae_test - mae_train:>8,.2f}
   â€¢ Diferencia RMSE (Train-Test): ${rmse_test - rmse_train:>8,.2f}
   â€¢ Diferencia RÂ² (Train-Test): {r2_test - r2_train:>11.4f}
   
âœ… Observaciones:
   - Residuos centrados en cero: {'SÃ' if abs(residuos_test.mean()) < 100 else 'NO'}
   - Modelo sin overfitting: {'SÃ' if abs(r2_test - r2_train) < 0.1 else 'POSIBLE'}
   - DistribuciÃ³n aproximadamente normal: {'SÃ' if abs(error_porcentual.skew()) < 1 else 'NO'}
"""

ax10.text(0.05, 0.95, resumen_text, transform=ax10.transAxes, 
         fontsize=9, verticalalignment='top', family='monospace',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()

# ============================================================================
# MOSTRAR GRÃFICAS
# ============================================================================

print("\nâœ… GrÃ¡ficas generadas correctamente")
print("\nğŸ¨ Mostrando visualizaciones...")
print("\n   - PÃ¡gina 1: AnÃ¡lisis Principal (6 grÃ¡ficas)")
print("   - PÃ¡gina 2: AnÃ¡lisis Complementario (4 grÃ¡ficas)")

plt.show()

# ============================================================================
# ESTADÃSTICAS ADICIONALES
# ============================================================================

print("\n" + "=" * 80)
print("ANÃLISIS ESTADÃSTICO COMPLETO")
print("=" * 80)

print(f"\nğŸ“Š DISTRIBUCIÃ“N DE PRECIOS:")
print(f"   Precio MÃ­nimo:    ${y.min():>12,.2f}")
print(f"   Precio MÃ¡ximo:    ${y.max():>12,.2f}")
print(f"   Precio Promedio:  ${y.mean():>12,.2f}")
print(f"   Desv. EstÃ¡ndar:   ${y.std():>12,.2f}")

print(f"\nğŸ“Š DISTRIBUCIÃ“N DE PREDICCIONES (TEST):")
print(f"   Min PredicciÃ³n:   ${y_pred_test.min():>12,.2f}")
print(f"   Max PredicciÃ³n:   ${y_pred_test.max():>12,.2f}")
print(f"   Promedio Pred:    ${y_pred_test.mean():>12,.2f}")
print(f"   Desv. EstÃ¡ndar:   ${y_pred_test.std():>12,.2f}")

print(f"\nğŸ¯ ANÃLISIS DE ERRORES:")
print(f"   Error MÃ­n:        ${errores_abs.min():>12,.2f}")
print(f"   Error MÃ¡x:        ${errores_abs.max():>12,.2f}")
print(f"   Error Med:        ${errores_abs.median():>12,.2f}")
print(f"   Error % MÃ­n:      {(np.abs(y_test - y_pred_test) / y_test * 100).min():>12.2f}%")
print(f"   Error % MÃ¡x:      {(np.abs(y_test - y_pred_test) / y_test * 100).max():>12.2f}%")

print(f"\nâœ… AnÃ¡lisis completado exitosamente\n")
